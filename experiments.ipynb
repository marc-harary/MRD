{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6c869-149c-4ea7-8e26-f1c67f3b987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import sys; sys.path.append(\".\")\n",
    "from mrd import core, data, models, callbacks\n",
    "import lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c5d83-83f7-45c6-9652-f0c163565d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "DATA_ROOT = \"./data_mnist\"\n",
    "\n",
    "WIDTH = 64           # <<<<< model size knob\n",
    "DEPTH = 1              # number of hidden blocks after the first\n",
    "USE_LAYERNORM = False\n",
    "ACTIVATION = \"gelu\"    # \"gelu\" or \"tanh\"\n",
    "D = 32\n",
    "\n",
    "TRAIN_BS = 4096\n",
    "TEST_BS = 4096\n",
    "DIAG_BS  = 4096\n",
    "\n",
    "LR = 0.01\n",
    "MOMENTUM = 1.0 # 0.9\n",
    "WEIGHT_DECAY = 0 # 1e-4\n",
    "NESTEROV = True\n",
    "GRAD_CLIP = None # 1.0\n",
    "\n",
    "MAX_STEPS = 400\n",
    "VAL_EVERY_N_STEPS = 200\n",
    "DIAG_EVERY_N_STEPS = 10\n",
    "DIAG_K = 16\n",
    "\n",
    "DEVICES = 1\n",
    "\n",
    "PRECISION = \"32-true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b36ff0-2583-41dc-b824-7f5dbdc3c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device=\"cpu\"); g.manual_seed(SEED)\n",
    "w = torch.randn(D, generator=g) / math.sqrt(D)\n",
    "A = torch.randn(D, D, generator=g) / math.sqrt(D)\n",
    "\n",
    "def f_star(X):  # X: (B,D)\n",
    "    return data.target_sin_mix(X, w=w, A=A)\n",
    "\n",
    "adm_cfg = data.AnalyticDMConfig(\n",
    "    d=D,\n",
    "    n_train=50_000,\n",
    "    n_test=10_000,\n",
    "    train_bs=TRAIN_BS,\n",
    "    test_bs=TEST_BS,\n",
    "    num_workers=1,\n",
    "    noise_std=0.05,\n",
    "    x_dist=\"normal\",\n",
    "    fixed_dataset=True,\n",
    "    standardize_x=True,   # “whiten-ish” inputs\n",
    ")\n",
    "\n",
    "dm = data.AnalyticRegressionData(adm_cfg, target_fn=f_star)\n",
    "dm.setup()\n",
    "\n",
    "# sanity check shapes\n",
    "xb, yb = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992ad91-6a6c-40e3-aa74-86d145159ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MLP(width=WIDTH, depth=DEPTH, in_dim=D, out_dim=1)\n",
    "\n",
    "module = models.MRDTaskModule(\n",
    "   model=model, task=\"regression\",\n",
    "    lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY, nesterov=NESTEROV\n",
    ")\n",
    "\n",
    "mrd_cb = callbacks.MRDDiagnosticsCallback(every_n_steps=DIAG_EVERY_N_STEPS, diag_bs=DIAG_BS, K=DIAG_K)\n",
    "\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "class NotebookTQDM(TQDMProgressBar):\n",
    "    def init_train_tqdm(self):\n",
    "        bar = super().init_train_tqdm()\n",
    "        bar.disable = False\n",
    "        return bar\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    devices=DEVICES,\n",
    "    precision=PRECISION,\n",
    "    limit_val_batches=0,\n",
    "    max_steps=MAX_STEPS,\n",
    "    gradient_clip_val=GRAD_CLIP,\n",
    "    log_every_n_steps=20,\n",
    "    val_check_interval=None,\n",
    "    enable_checkpointing=False,\n",
    "    enable_model_summary=True,\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[NotebookTQDM(refresh_rate=20), mrd_cb],\n",
    "    logger=False,   # keep notebook simple; metrics stored in mrd_cb.rows\n",
    ")\n",
    "\n",
    "trainer.fit(module, datamodule=dm)\n",
    "trainer.test(module, datamodule=dm)\n",
    "\n",
    "df = mrd_cb.dataframe()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312f754-3fd2-4277-91df-ee7a6cf3a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df[\"step\"], df.get(\"loss\", pd.Series([float(\"nan\")]*len(df))), label=\"loss\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Metric vs Residual (exact, tiny batch)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[\"step\"], df.get(\"H_model_F\", pd.Series([float(\"nan\")]*len(df))), label=\"||H_model||_F\")\n",
    "plt.plot(df[\"step\"], df.get(\"H_mix_F\", pd.Series([float(\"nan\")]*len(df))), label=\"||H||_F\")\n",
    "plt.plot(df[\"step\"], df.get(\"G_F\", pd.Series([float(\"nan\")]*len(df))), label=\"||G||_F\")\n",
    "plt.plot(df[\"step\"], df.get(\"R_F\", pd.Series([float(\"nan\")]*len(df))), label=\"||R||_F\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Frobenius norm\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Metric vs Residual (exact, tiny batch)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[\"step\"], df.get(\"Phi_align_F_fd\", pd.Series([float(\"nan\")]*len(df))), label=\"||Phi_align||_F\")\n",
    "plt.plot(df[\"step\"], df.get(\"Phi_damp_F_fd\", pd.Series([float(\"nan\")]*len(df))), label=\"||Phi_damp||_F\")\n",
    "plt.plot(df[\"step\"], df.get(\"Phi_trans_F_fd\", pd.Series([float(\"nan\")]*len(df))), label=\"||Phi_trans||_F\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Frobenius norm\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Three-channel magnitudes (exact, tiny batch)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df[\"step\"], df.get(\"m_F\", pd.Series([float(\"nan\")]*len(df))))\n",
    "plt.axhline(0.0, linestyle=\"--\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"m_F\")\n",
    "plt.title(\"Frobenius margin m_F (exact, tiny batch)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbb493-bc6e-45ab-83fc-11a37d8afc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set this to match your run\n",
    "TASK = \"regression\"        # \"regression\" or \"classification\"\n",
    "EPS = 1e-12\n",
    "\n",
    "steps = df[\"step\"].to_numpy()\n",
    "\n",
    "def col(name, default=np.nan):\n",
    "    if name in df.columns:\n",
    "        return df[name].to_numpy()\n",
    "    return np.full(len(df), default, dtype=float)\n",
    "\n",
    "# --- loss\n",
    "loss = col(\"loss\", np.nan)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(steps, loss, label=\"loss\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- metric vs residual + (optional) model-curvature proxy\n",
    "G_F = col(\"G_F\", np.nan)\n",
    "R_F = col(\"R_F\", np.nan)\n",
    "\n",
    "# If you *actually* logged a direct model-curvature estimate, use it.\n",
    "# Suggested column names (pick one in your diagnostics code):\n",
    "#   \"H_model_F\"  or \"Hbar_F\"  or \"H_F\"\n",
    "H_model = None\n",
    "for name in [\"H_model_F\", \"Hbar_F\", \"H_F\"]:\n",
    "    if name in df.columns:\n",
    "        H_model = df[name].to_numpy()\n",
    "        H_model_label = name\n",
    "        break\n",
    "\n",
    "# Otherwise build a cheap proxy from what you already logged.\n",
    "# Regression: R = E[e H] => ||E[H]||_F is (very crudely) ~ ||R||_F / E|e|.\n",
    "# We can upper-bound E|e| by sqrt(E[e^2]) = sqrt(MSE). If \"loss\" is MSE, use sqrt(loss).\n",
    "H_proxy = None\n",
    "H_proxy_label = None\n",
    "if H_model is None and TASK == \"regression\" and np.isfinite(loss).any():\n",
    "    e_rms = np.sqrt(np.maximum(loss, 0.0))  # sqrt(MSE)\n",
    "    H_proxy = R_F / (e_rms + EPS)\n",
    "    H_proxy_label = \"||R||_F / sqrt(MSE)  (proxy for ||E[H]||_F)\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(steps, G_F, label=\"||G||_F\")\n",
    "plt.plot(steps, R_F, label=\"||R||_F\")\n",
    "\n",
    "if H_model is not None:\n",
    "    plt.plot(steps, H_model, label=H_model_label)\n",
    "elif H_proxy is not None:\n",
    "    plt.plot(steps, H_proxy, label=H_proxy_label)\n",
    "\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Frobenius norm / proxy\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Metric vs Residual + Model Curvature\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- channels\n",
    "Pa = col(\"Phi_align_F_fd\", np.nan)\n",
    "Pd = col(\"Phi_damp_F_fd\", np.nan)\n",
    "Pt = col(\"Phi_trans_F_fd\", np.nan)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(steps, Pa, label=\"||Phi_align||_F\")\n",
    "plt.plot(steps, Pd, label=\"||Phi_damp||_F\")\n",
    "plt.plot(steps, Pt, label=\"||Phi_trans||_F\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Frobenius norm\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Three-channel magnitudes\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Frobenius margin\n",
    "m_F = col(\"m_F\", np.nan)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(steps, m_F, label=\"m_F\")\n",
    "plt.axhline(0.0, linestyle=\"--\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"m_F\")\n",
    "plt.title(\"Frobenius margin m_F\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd42261-66c4-4764-8235-0ca80ce19397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc670b-325d-4ccb-ba45-7686cc4e9c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
